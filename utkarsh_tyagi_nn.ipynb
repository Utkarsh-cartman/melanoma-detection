{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ca95633-4546-4c05-bb65-8de8d35766d2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/9e/b8/ed5f794359d05cd0bffb894c6418da87b93016ee17b669d55c45d1bd5d5b/tensorflow-2.13.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Using cached tensorflow-2.13.0-cp311-cp311-win_amd64.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: tensorflow-intel==2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.13.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.1.21 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.24.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.56.2)\n",
      "Requirement already satisfied: tensorboard<2.14,>=2.13 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.14,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.0)\n",
      "Requirement already satisfied: keras<2.14,>=2.13.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (2.13.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Using cached tensorflow-2.13.0-cp311-cp311-win_amd64.whl (1.9 kB)\n",
      "Installing collected packages: tensorflow\n",
      "Successfully installed tensorflow-2.13.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a64981b5-b9bb-4cb1-ae66-20bb53882e71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google.colab\n",
      "  Using cached google-colab-1.0.0.tar.gz (72 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting google-auth~=1.4.0 (from google.colab)\n",
      "  Using cached google_auth-1.4.2-py2.py3-none-any.whl (64 kB)\n",
      "Collecting ipykernel~=4.6.0 (from google.colab)\n",
      "  Using cached ipykernel-4.6.1-py3-none-any.whl (104 kB)\n",
      "Collecting ipython~=5.5.0 (from google.colab)\n",
      "  Using cached ipython-5.5.0-py3-none-any.whl (758 kB)\n",
      "Collecting notebook~=5.2.0 (from google.colab)\n",
      "  Using cached notebook-5.2.2-py2.py3-none-any.whl (8.0 MB)\n",
      "Collecting six~=1.12.0 (from google.colab)\n",
      "  Using cached six-1.12.0-py2.py3-none-any.whl (10 kB)\n",
      "Collecting pandas~=0.24.0 (from google.colab)\n",
      "  Using cached pandas-0.24.2.tar.gz (11.8 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [15 lines of output]\n",
      "  C:\\Users\\UTKARSH\\AppData\\Local\\Temp\\pip-install-jzmc3a3i\\pandas_e5def5394a814e7eab977d7338069d8e\\setup.py:12: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "    import pkg_resources\n",
      "  C:\\ProgramData\\anaconda3\\Lib\\site-packages\\setuptools\\__init__.py:84: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "  !!\n",
      "  \n",
      "          ********************************************************************************\n",
      "          Requirements should be satisfied by a PEP 517 installer.\n",
      "          If you are using pip, you can try `pip install --use-pep517`.\n",
      "          ********************************************************************************\n",
      "  \n",
      "  !!\n",
      "    dist.fetch_build_eggs(dist.setup_requires)\n",
      "  error in pandas setup command: 'install_requires' must be a string or list of strings containing valid project/version requirement specifiers; Expected end or semicolon (after version specifier)\n",
      "      pytz >= 2011k\n",
      "           ~~~~~~~^\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "pip install google.colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57639003-65aa-4c0a-8c13-4252df7b9c40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: C:\\ProgramData\\anaconda3\n",
      "\n",
      "  added / updated specs:\n",
      "    - google-colab\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2023.7.22  |       h56e8100_0         146 KB  conda-forge\n",
      "    cachetools-5.3.1           |     pyhd8ed1ab_0          14 KB  conda-forge\n",
      "    certifi-2023.7.22          |     pyhd8ed1ab_0         150 KB  conda-forge\n",
      "    conda-23.7.2               |  py311h1ea47a8_0         1.3 MB  conda-forge\n",
      "    google-auth-2.22.0         |     pyh1a96a4e_0         100 KB  conda-forge\n",
      "    google-colab-1.0.0         |     pyh44b312d_0          77 KB  conda-forge\n",
      "    openssl-1.1.1v             |       h2bbff1b_0         5.5 MB\n",
      "    portpicker-1.5.2           |     pyhd8ed1ab_0          17 KB  conda-forge\n",
      "    python_abi-3.11            |          2_cp311           5 KB  conda-forge\n",
      "    pyu2f-0.1.5                |     pyhd8ed1ab_0          31 KB  conda-forge\n",
      "    rsa-4.9                    |     pyhd8ed1ab_0          29 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         7.3 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  cachetools         conda-forge/noarch::cachetools-5.3.1-pyhd8ed1ab_0 \n",
      "  google-auth        conda-forge/noarch::google-auth-2.22.0-pyh1a96a4e_0 \n",
      "  google-colab       conda-forge/noarch::google-colab-1.0.0-pyh44b312d_0 \n",
      "  portpicker         conda-forge/noarch::portpicker-1.5.2-pyhd8ed1ab_0 \n",
      "  python_abi         conda-forge/win-64::python_abi-3.11-2_cp311 \n",
      "  pyu2f              conda-forge/noarch::pyu2f-0.1.5-pyhd8ed1ab_0 \n",
      "  rsa                conda-forge/noarch::rsa-4.9-pyhd8ed1ab_0 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2023.05.30~ --> conda-forge::ca-certificates-2023.7.22-h56e8100_0 \n",
      "  openssl                                 1.1.1u-h2bbff1b_0 --> 1.1.1v-h2bbff1b_0 \n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  certifi            pkgs/main/win-64::certifi-2023.7.22-p~ --> conda-forge/noarch::certifi-2023.7.22-pyhd8ed1ab_0 \n",
      "  conda              pkgs/main::conda-23.7.2-py311haa95532~ --> conda-forge::conda-23.7.2-py311h1ea47a8_0 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "\n",
      "certifi-2023.7.22    | 150 KB    |            |   0% \n",
      "\n",
      "conda-23.7.2         | 1.3 MB    |            |   0% \u001b[A\n",
      "\n",
      "\n",
      "google-auth-2.22.0   | 100 KB    |            |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "cachetools-5.3.1     | 14 KB     |            |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "portpicker-1.5.2     | 17 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "google-colab-1.0.0   | 77 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "rsa-4.9              | 29 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1v       | 5.5 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python_abi-3.11      | 5 KB      |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 146 KB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pyu2f-0.1.5          | 31 KB     |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "cachetools-5.3.1     | 14 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "conda-23.7.2         | 1.3 MB    | 1          |   1% \u001b[A\n",
      "certifi-2023.7.22    | 150 KB    | #          |  11% \n",
      "\n",
      "\n",
      "google-auth-2.22.0   | 100 KB    | #6         |  16% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "cachetools-5.3.1     | 14 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "conda-23.7.2         | 1.3 MB    | ###4       |  34% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "rsa-4.9              | 29 KB     | #####4     |  55% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "certifi-2023.7.22    | 150 KB    | ########## | 100% \n",
      "certifi-2023.7.22    | 150 KB    | ########## | 100% \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1v       | 5.5 MB    |            |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 146 KB    | #          |  11% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "rsa-4.9              | 29 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "rsa-4.9              | 29 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1v       | 5.5 MB    | 7          |   8% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "google-auth-2.22.0   | 100 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "google-auth-2.22.0   | 100 KB    | ########## | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 146 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ca-certificates-2023 | 146 KB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "portpicker-1.5.2     | 17 KB     | #########3 |  94% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1v       | 5.5 MB    | #######2   |  73% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "portpicker-1.5.2     | 17 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python_abi-3.11      | 5 KB      | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "google-colab-1.0.0   | 77 KB     | ##         |  21% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "python_abi-3.11      | 5 KB      | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pyu2f-0.1.5          | 31 KB     | #####1     |  51% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "google-colab-1.0.0   | 77 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "google-colab-1.0.0   | 77 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pyu2f-0.1.5          | 31 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pyu2f-0.1.5          | 31 KB     | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-1.1.1v       | 5.5 MB    | ########## | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "conda-23.7.2         | 1.3 MB    | ########## | 100% \u001b[A\n",
      "\n",
      "conda-23.7.2         | 1.3 MB    | ########## | 100% \u001b[A\n",
      "                                                     \n",
      "\n",
      "\n",
      "                                                     \u001b[A\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                     \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "Preparing transaction: ...working... done\n",
      "Executing transaction: ...working... done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): conda.anaconda.org:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): conda.anaconda.org:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/msys2/noarch/current_repodata.json HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/noarch/current_repodata.json HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/noarch/current_repodata.json HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/win-64/current_repodata.json HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/r/win-64/current_repodata.json HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://conda.anaconda.org:443 \"GET /conda-forge/noarch/current_repodata.json HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/msys2/win-64/current_repodata.json HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:https://conda.anaconda.org:443 \"GET /conda-forge/win-64/current_repodata.json HTTP/1.1\" 200 None\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): conda.anaconda.org:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): conda.anaconda.org:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): conda.anaconda.org:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): conda.anaconda.org:443\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): conda.anaconda.org:443\n",
      "DEBUG:urllib3.connectionpool:https://conda.anaconda.org:443 \"GET /conda-forge/noarch/cachetools-5.3.1-pyhd8ed1ab_0.conda HTTP/1.1\" 200 14630\n",
      "DEBUG:urllib3.connectionpool:https://conda.anaconda.org:443 \"GET /conda-forge/win-64/conda-23.7.2-py311h1ea47a8_0.conda HTTP/1.1\" 200 1347140\n",
      "DEBUG:urllib3.connectionpool:https://conda.anaconda.org:443 \"GET /conda-forge/noarch/certifi-2023.7.22-pyhd8ed1ab_0.conda HTTP/1.1\" 200 153791\n",
      "DEBUG:urllib3.connectionpool:https://conda.anaconda.org:443 \"GET /conda-forge/noarch/google-auth-2.22.0-pyh1a96a4e_0.conda HTTP/1.1\" 200 102076\n",
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): repo.anaconda.com:443\n",
      "DEBUG:urllib3.connectionpool:https://conda.anaconda.org:443 \"GET /conda-forge/noarch/rsa-4.9-pyhd8ed1ab_0.tar.bz2 HTTP/1.1\" 200 29863\n",
      "DEBUG:urllib3.connectionpool:https://repo.anaconda.com:443 \"GET /pkgs/main/win-64/openssl-1.1.1v-h2bbff1b_0.conda HTTP/1.1\" 200 5773548\n",
      "DEBUG:urllib3.connectionpool:https://conda.anaconda.org:443 \"GET /conda-forge/win-64/ca-certificates-2023.7.22-h56e8100_0.conda HTTP/1.1\" 200 150013\n",
      "DEBUG:urllib3.connectionpool:https://conda.anaconda.org:443 \"GET /conda-forge/noarch/portpicker-1.5.2-pyhd8ed1ab_0.tar.bz2 HTTP/1.1\" 200 17491\n",
      "DEBUG:urllib3.connectionpool:https://conda.anaconda.org:443 \"GET /conda-forge/win-64/python_abi-3.11-2_cp311.tar.bz2 HTTP/1.1\" 200 5083\n",
      "DEBUG:urllib3.connectionpool:https://conda.anaconda.org:443 \"GET /conda-forge/noarch/google-colab-1.0.0-pyh44b312d_0.tar.bz2 HTTP/1.1\" 200 78980\n",
      "DEBUG:urllib3.connectionpool:https://conda.anaconda.org:443 \"GET /conda-forge/noarch/pyu2f-0.1.5-pyhd8ed1ab_0.tar.bz2 HTTP/1.1\" 200 31876\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge google-colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3f11dfb-885e-47d6-9023-aa6b4a6f648b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'terminos'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mterminos\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#mount google drive\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'terminos'"
     ]
    }
   ],
   "source": [
    "import terminos\n",
    "#mount google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a836f5eb-d54e-4b31-b0e6-013ff9e96c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bee5e1c-4135-4005-881f-85cfebc6bdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the path for train and test images\n",
    "data_dir_train = pathlib.Path(r\"/melanoma detection/Skin cancer ISIC The International Skin Imaging Collaboration/Train/\")\n",
    "data_dir_test = pathlib.Path(r\"/melanoma detection/Skin cancer ISIC The International Skin Imaging Collaboration/Test/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fac14c2-f8d2-4914-9b7c-9b4022d44a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Count the number of image in Train and Test directory\n",
    "# Using the glob to retrieve files/pathnames matching a specified pattern.\n",
    "\n",
    "#Train Image count\n",
    "image_count_train = len(list(data_dir_train.glob('*/*.jpg')))\n",
    "print(image_count_train)\n",
    "\n",
    "#Test Image count\n",
    "image_count_test = len(list(data_dir_test.glob('*/*.jpg')))\n",
    "print(image_count_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a6c968-3521-4b5e-a907-78db9f9e92fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of image in Train and Test directory\n",
    "# Using the glob to retrieve files/pathnames matching a specified pattern.\n",
    "\n",
    "#Train Image count\n",
    "image_count_train = len(list(data_dir_train.glob('*/*.jpg')))\n",
    "print(image_count_train)\n",
    "\n",
    "#Test Image count\n",
    "image_count_test = len(list(data_dir_test.glob('*/*.jpg')))\n",
    "print(image_count_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a2c96f-2860-4a53-9bce-b6cc7e12e552",
   "metadata": {},
   "source": [
    "Data visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74d7572-5060-4d09-bbce-c4a1f6ec1d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize one instance of all the class present in the dataset.\n",
    "\n",
    "#image_dataset_from_directory() will return a tf.data.Dataset that yields batches of images from the subdirectories.\n",
    "#label_mode is categorial, the labels are a float32 tensor of shape (batch_size, num_classes), representing a one-hot encoding of the class index.\n",
    "image_dataset = tf.keras.preprocessing.image_dataset_from_directory(data_dir_train,batch_size=32,image_size=(180,180),\n",
    "                                                                    label_mode='categorical',seed=123)\n",
    "\n",
    "#all the classes of Skin Cancer\n",
    "class_names = image_dataset.class_names\n",
    "\n",
    "#Dictionary to store the path of image as per the class\n",
    "files_path_dict = {}\n",
    "\n",
    "for c in class_names:\n",
    "    files_path_dict[c] = list(map(lambda x:str(data_dir_train)+'/'+c+'/'+x,os.listdir(str(data_dir_train)+'/'+c)))\n",
    "    \n",
    "#Visualize image \n",
    "plt.figure(figsize=(15,15))\n",
    "index = 0\n",
    "for c in class_names:\n",
    "    path_list = files_path_dict[c][:1]\n",
    "    index += 1\n",
    "    plt.subplot(3,3,index)\n",
    "    plt.imshow(load_img(path_list[0],target_size=(180,180)))\n",
    "    plt.title(c)\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773a0673-9d8a-4e33-a8a8-374a62b9c302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def class_distribution_count(directory):\n",
    "    \n",
    "    #count number of image in each classes\n",
    "    count= []\n",
    "    for path in pathlib.Path(directory).iterdir():\n",
    "        if path.is_dir():\n",
    "            count.append(len([name for name in os.listdir(path)\n",
    "                               if os.path.isfile(os.path.join(path, name))]))\n",
    "    \n",
    "    #name of the classes\n",
    "    sub_directory = [name for name in os.listdir(directory)\n",
    "                    if os.path.isdir(os.path.join(directory, name))]\n",
    "    \n",
    "    #return dataframe with image count and class.\n",
    "    return pd.DataFrame(list(zip(sub_directory,count)),columns =['Class', 'No. of Image'])\n",
    "\n",
    "df = class_distribution_count(data_dir_train)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0664477-fd2a-4e69-bb18-f281ad78e61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the Number of image in each class.\n",
    "import seaborn as sns\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x=\"No. of Image\", y=\"Class\", data=df,\n",
    "            label=\"Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11de8f3d-8864-4bde-91aa-4185afe30d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install Augmentor\n",
    "!pip install Augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c683e9e-6d2c-4a6b-ae69-78f6ce8db7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_training_dataset=\"/content/Skin cancer ISIC The International Skin Imaging Collaboration/Train/\"\n",
    "import Augmentor\n",
    "for i in class_names:\n",
    "    p = Augmentor.Pipeline(path_to_training_dataset + i)\n",
    "    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
    "    p.sample(500)  #Adding 500 samples per class to make sure that none of the classes are sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a01426-a848-4767-9279-26d99d5dfed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count total number of image generated by Augmentor.\n",
    "image_count_train = len(list(data_dir_train.glob('*/output/*.jpg')))\n",
    "print(image_count_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49670927-fc7f-4eb3-9fab-a1e0c1df4eab",
   "metadata": {},
   "source": [
    "MODEL BUILDING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973af622-538b-47e2-a981-1e2ebe7454ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train dataset \n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(data_dir_train, batch_size=32,\n",
    "                                                               image_size=(180,180), label_mode='categorical',\n",
    "                                                               seed=123,subset=\"training\",\n",
    "                                                               validation_split=0.2)\n",
    "\n",
    "#label_mode is categorial, the labels are a float32 tensor of shape (batch_size, num_classes),\n",
    "#representing a one-hot encoding of the class index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1299b67c-b70a-4a59-8841-3b4811d3e191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation dataset \n",
    "val_ds =tf.keras.preprocessing.image_dataset_from_directory(data_dir_train,batch_size=32,\n",
    "                                                            image_size=(180,180), label_mode='categorical',\n",
    "                                                            seed=123,subset=\"validation\",\n",
    "                                                            validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a64812f-4340-459b-8b31-4414b1a6d04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.data.experimental.AUTOTUNE defines appropriate number of processes that are free for working.\n",
    "\n",
    "#`Dataset.cache()` keeps the images in memory after they're loaded off disk during the first epoch.\n",
    "\n",
    "#`Dataset.prefetch()` overlaps data preprocessing and model execution while training.\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eafb063-6c8f-4d2e-85c1-b4a1829cf72a",
   "metadata": {},
   "source": [
    "MODEL ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf15f45-01b1-41db-80ee-44c9297bf5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#CNN Model Architecture\n",
    "\n",
    "#Sequential allows you to create models layer-by-layer  \n",
    "model = Sequential()\n",
    "\n",
    "model.add(layers.experimental.preprocessing.Rescaling(1./255,input_shape=(180,180,3)))   #Rescaling Layer\n",
    "\n",
    "#First Convulation layer\n",
    "model.add(layers.Conv2D(32,kernel_size=(3,3),activation='relu'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "#Second Convulation Layer\n",
    "model.add(layers.Conv2D(64,kernel_size=(3,3),activation='relu'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "#Third Convulation Layer\n",
    "model.add(layers.Conv2D(128,kernel_size=(3,3),activation='relu'))\n",
    "model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "\n",
    "#Dropout layer with 50% Fraction of the input units to drop.\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "#Flatten Layer\n",
    "##Keras.layers.flatten function flattens the multi-dimensional input tensors into a single dimension.\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "#Dense Layer\n",
    "model.add(layers.Dense(128,activation='relu'))\n",
    "\n",
    "#Dropout layer with 25% Fraction of the input units to drop.\n",
    "model.add(layers.Dropout(0.25))\n",
    "\n",
    "#Dense Layer with softmax activation function.\n",
    "#Softmax is an activation function that scales numbers/logits into probabilities.\n",
    "model.add(layers.Dense(len(class_names),activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681836d5-9760-4d02-a0e4-5c6e13fc98eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vizualizing the model \n",
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04dc736-5905-4269-be3f-fa7cd7fac76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile the Model\n",
    "\n",
    "#Adam optimization: is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments.\n",
    "#categorical_crossentropy: Used as a loss function for multi-class classification model where there are two or more output labels.\n",
    "\n",
    "model.compile(optimizer=\"Adam\",loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "\n",
    "#ModelCheckpoint callback is used in conjunction with training using model.fit() to save a model or weights (in a checkpoint file) at some interval,\n",
    "#so the model or weights can be loaded later to continue the training from the state saved.\n",
    "checkpoint = ModelCheckpoint(\"model.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
    "\n",
    "#Stop training when a monitored metric has stopped improving.\n",
    "earlystop = EarlyStopping(monitor=\"val_accuracy\",patience=5,mode=\"auto\",verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b709fc-932c-4120-9564-32988cd8db81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "epochs = 20\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=epochs,callbacks=[checkpoint,earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10df377-3712-42af-8eb5-3c24ff200b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the training curves\n",
    "\n",
    "epochs_range = range(earlystop.stopped_epoch+1)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "#Plot Model Accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel(epochs_range)\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "\n",
    "#Plot Model Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel(epochs_range)\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fb67ae-cee1-4a20-a799-eaa78d9343c9",
   "metadata": {},
   "source": [
    "Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be477c51-49ec-4d38-9f9e-1d229234a772",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "Test_image_path = os.path.join(data_dir_test, class_names[1], '*')\n",
    "Test_image = glob(Test_image_path)\n",
    "Test_image = load_img(Test_image[-1],target_size=(180,180,3))\n",
    "plt.imshow(Test_image)\n",
    "plt.grid(False)\n",
    "\n",
    "img = np.expand_dims(Test_image,axis=0)\n",
    "pred = model.predict(img)\n",
    "pred = np.argmax(pred)\n",
    "pred_class = class_names[pred]\n",
    "print(\"Actual Class \"+ class_names[1] +'\\n'+ \"Predictive Class \"+pred_class )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
